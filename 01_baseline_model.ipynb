{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Prediction Baseline Model\n",
    "Using our real ASOS Graphics + TheLook e-commerce data from our group project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the exact files you just added\n",
    "orders       = pd.read_csv('data/orders.csv')\n",
    "order_items  = pd.read_csv('data/order_items.csv')\n",
    "products     = pd.read_csv('data/products.csv')\n",
    "users        = pd.read_csv('data/users.csv')\n",
    "\n",
    "# If you have a separate returns file (some versions do)\n",
    "try:\n",
    "    returns = pd.read_csv('data/returns.csv')\n",
    "    print(\"returns.csv found – using real return labels\")\n",
    "except:\n",
    "    returns = None\n",
    "    print(\"No returns.csv – will create proxy from status\")\n",
    "\n",
    "print(f\"Orders: {orders.shape}\")\n",
    "print(f\"Order items: {order_items.shape}\")\n",
    "print(f\"Products: {products.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything\n",
    "df = order_items.merge(order_items, on='order_id', how='left')\n",
    "df = df.merge(products, on='product_id', how='left')\n",
    "df = df.merge(users, on='user_id', how='left')\n",
    "\n",
    "# Create target variable – this matches what your group did\n",
    "if returns is not None:\n",
    "    df = df.merge(returns[['order_id', 'returned']], on='order_id', how='left')\n",
    "    df['is_returned'] = df['returned'].fillna(0).astype(int)\n",
    "else:\n",
    "    # Proxy most groups used\n",
    "    df['is_returned'] = df['status'].isin(['Returned', 'Cancelled', 'Returned']).astype(int)\n",
    "\n",
    "print(f\"Final dataset: {df.shape}\")\n",
    "print(f\"Return rate: {df['is_returned'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering – exactly the ones your group found important\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['delivered_at'] = pd.to_datetime(df['delivered_at'])\n",
    "df['delivery_time_days'] = (df['delivered_at'] - df['created_at']).dt.days.fillna(30)\n",
    "\n",
    "features = [\n",
    "    'sale_price', 'cost', 'retail_price',\n",
    "    'delivery_time_days',\n",
    "    'category', 'department', 'brand',\n",
    "    'age', 'traffic_source'\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['is_returned']\n",
    "\n",
    "# Simple encoding\n",
    "X = pd.get_dummies(X, columns=['category', 'department', 'brand', 'traffic_source'], drop_first=True)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(len(y_train)-y_train.sum())/y_train.sum(),\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== MODEL RESULTS ===\")\n",
    "print(f\"F1-score  : {f1_score(y_test, preds):.3f}\")\n",
    "print(f\"ROC-AUC   : {roc_auc_score(y_test, probs):.3f}\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for FastAPI & Streamlit\n",
    "model.save_model('src/model/return_predictor.json')\n",
    "print(\"Model saved → src/model/return_predictor.json\")\n",
    "\n",
    "# Also save feature list for the API later\n",
    "import joblib\n",
    "joblib.dump(list(X.columns), 'src/model/feature_names.pkl')\n",
    "print(\"Feature names saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
